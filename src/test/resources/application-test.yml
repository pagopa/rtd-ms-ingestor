logging:
  level:
    root: INFO

ingestor:
  anonymizePaymentInstrument: true
  contractIdObfuscationHmacKey: ${CONTRACT_ID_OBFUSCATION_HMAC_KEY:nXegOrPs5wrRPOM6VNOlkxT3PPjruUk5ppohs6fIVQk=}
  resources:
    base:
      path: src/test/resources
  api:
    baseurl: https://${CSV_TRANSACTION_DECRYPT_HOST:internal.it}
    wallet:
      baseurl: https://${WALLET_HOST:wallet.it}
      updateContracts: /payment-wallet-migrations/cstar/v1/migrations/wallets/updateDetails
      deleteContracts: /payment-wallet-migrations/cstar/v1/migrations/wallets/delete
      readTimeout: ${WALLET_READ_TIMEOUT:10000}
      connectionTimeout: ${WALLET_CONNECTION_TIMEOUT:10000}
      apikey: ${WALLET_API_KEY:myapikey}
      rateLimit: ${WALLET_RATE_LIMIT:1}
      rateLimitTimeoutMilliSeconds: ${WALLET_RATE_LIMIT_TIMEOUT_MS:200}
      limitRefreshPeriodMilliSeconds: ${WALLET_REFRESH_PERIOD_MS:20}
      maxRetryAttempt: ${WALLET_MAX_RETRIES:3}
      retryMaxIntervalMilliSeconds: ${WALLET_RETRY_MAX_INTERVAL_MS:10}
      threadPool: ${THREAD_POOL:25}
      connectionPool: ${CONNECTION_POOL:25}
  blobclient:
    basepath: storage
    apikey: ${INTERNAL_SERVICES_API_KEY:myapikey}
    sourceContainer: rtd-transactions-decrypted
# kafka:
#   binder:
#     brokers: ${KAFKA_BROKER:localhost}

---
spring:
  config:
    activate:
      on-profile: test
  cloud:
    function:
      definition: blobStorageConsumer
    stream:
      source: rtdTrxProducer
      bindings:
        blobStorageConsumer-in-0: # name must match [handler name]-in-0
          destination: rtd-platform-events
          group: rtd-ingestor-consumer-group
          content-type: application/json
          binder: blob-storage
        rtdTrxProducer-out-0: # name must match [handler name]-out-0
          destination: rtd-trx
          binder: rtd-trx
        rtdTrxConsumer-in-0: # name must match [handler name]-out-0
          group: rtd-trx
          destination: rtd-trx
          binder: rtd-trx
      binders:
        rtd-trx:
          type: kafka
          environment:
            spring:
              cloud:
                stream:
                  kafka:
                    binder:
                      auto-create-topics: false
                      brokers: ${spring.embedded.kafka.brokers}
                      # consumerProperties:
                      #   key:
                      #     deserializer: org.apache.kafka.common.serialization.StringDeserializer
                      #   value:
                      #     deserializer: org.apache.kafka.common.serialization.StringDeserializer
        blob-storage:
          type: kafka
          environment:
            spring:
              cloud:
                stream:
                  kafka:
                    binder:
                      auto-create-topics: false
                      brokers: ${spring.embedded.kafka.brokers}
                      consumerProperties:
                        key:
                          deserializer: org.apache.kafka.common.serialization.StringDeserializer
                        value:
                          deserializer: org.apache.kafka.common.serialization.StringDeserializer
---
spring:
  config:
    activate:
      on-profile: mongo-integration-test
# ---
# spring:
#   config:
#     activate:
#       on-profile: default
#   cloud:
#     stream:
#       bindings:
#         blobStorageConsumer-in-0: # name must match [handler name]-in-0
#           destination: rtd-platform-events
#           group: rtd-ingestor-consumer-group
#           content-type: application/json
#           binder: blob-storage-consumer
#         rtdTrxProducer-out-0: # name must match [handler name]-out-0
#           destination: rtd-trx
#           binder: rtd-trx-producer
#       binders:
#         blob-storage-consumer:
#           type: kafka
#           environment:
#             auto-create-topics: false
#             brokers: ${KAFKA_BROKER}
#             configuration:
#               sasl:
#                 jaas:
#                   config: ${KAFKA_SASL_JAAS_CONFIG_CONSUMER_BLOB_STORAGE_EVENTS}
#                 mechanism: PLAIN
#               security:
#                 protocol: SASL_SSL
#             consumerProperties:
#               key:
#                 deserializer: org.apache.kafka.common.serialization.StringDeserializer
#               value:
#                 deserializer: org.apache.kafka.common.serialization.StringDeserializer
#               socket:
#                 connection:
#                   setup:
#                     timeout:
#                       max:
#                         ms: 200000
#                       ms: 100000
#               request:
#                 timeout:
#                   ms: 60000
#               connections:
#                 max:
#                   idle:
#                     ms: 180000
#               max:
#                 partition:
#                   fetch:
#                     bytes: 10485760
#               session:
#                 timeout:
#                   ms: 10000
#               metadata:
#                 max:
#                   age:
#                     ms: 180000
#               # partition:
#               #   assignment:
#               #     strategy: org.apache.kafka.clients.consumer.RangeAssignor
#         rtd-trx-producer:
#           type: kafka
#           environment:
#             auto-create-topics: false
#             brokers: ${KAFKA_BROKER}
#             configuration:
#               sasl:
#                 jaas:
#                   config: ${KAFKA_SASL_JAAS_CONFIG_PRODUCER_RTD_TRX}
#                 mechanism: PLAIN
#               security:
#                 protocol: SASL_SSL
#             consumerProperties:
#               # key:
#               #   deserializer: org.apache.kafka.common.serialization.StringDeserializer
#               # value:
#               #   deserializer: org.apache.kafka.common.serialization.StringDeserializer
#               socket:
#                 connection:
#                   setup:
#                     timeout:
#                       max:
#                         ms: 200000
#                       ms: 100000
#               request:
#                 timeout:
#                   ms: 60000
#               connections:
#                 max:
#                   idle:
#                     ms: 180000
#               max:
#                 partition:
#                   fetch:
#                     bytes: 10485760
#               session:
#                 timeout:
#                   ms: 10000
#               metadata:
#                 max:
#                   age:
#                     ms: 180000
#               # partition:
#               #   assignment:
#               #     strategy: org.apache.kafka.clients.consumer.RangeAssignor
