logging:
  level:
    root: INFO

# Expose only health probes
management:
  metrics.export.defaults.enabled: false
  info.defaults.enabled: false
  endpoints.enabled-by-default: false
  endpoint:
    health:
      enabled: true
      probes:
        enabled: true

ingestor:
  resources:
    base:
      path: src/test/resources
  api:
    baseurl: https://${CSV_INGESTOR_HOST:internal.it}
  blobclient:
    basepath: storage
    apikey: ${INTERNAL_SERVICES_API_KEY:myapikey}
    sourceContainer: rtd-transactions-decrypted

---
spring:
  config:
    activate:
      on-profile: default
  data:
    mongodb:
      uri: ${MONGODB_CONNECTION_URI:mongodb://localhost:27017}
      database: ${MONGODB_NAME:rtd}
  cloud:
    stream:
      source: rtdTrxProducer
      function:
        definition: blobStorageConsumer;rtdDlqTrxConsumer
      bindings:
        blobStorageConsumer-in-0: # name must match [handler name]-in-0
          destination: rtd-platform-events
          group: rtd-ingestor-consumer-group
          content-type: application/json
          binder: blob-storage
        rtdTrxProducer-out-0: # name must match [handler name]-out-0
          destination: rtd-trx
          content-type: application/json
          binder: rtd-trx
        rtdDlqTrxConsumer-in-0:
          destination: rtd-dlq-trx
          group: rtd-ingestor-dlq-consumer-group
          content-type: application/json
          binder: rtd-dlq-trx-consumer
        rtdDlqTrxProducer-out-0:
          destination: rtd-dlq-trx
          content-type: application/json
          binder: rtd-dlq-trx-producer
      binders:
        rtd-trx:
          type: kafka
          environment:
            spring:
              cloud:
                stream:
                  kafka:
                    binder:
                      auto-create-topics: false
                      brokers: ${KAFKA_BROKER://localhost:29095}
                      configuration:
                        sasl:
                          jaas:
                            config: ${KAFKA_SASL_JAAS_CONFIG_PRODUCER_RTD_TRX}
                          mechanism: PLAIN
                        security:
                          protocol: SASL_SSL
                        default.key.serde: org.apache.kafka.common.serialization.Serdes$StringSerde
                        default.value.serde: org.apache.kafka.common.serialization.Serdes$StringSerde
        rtd-dlq-trx-producer:
          type: kafka
          environment:
            spring:
              cloud:
                stream:
                  kafka:
                    binder:
                      auto-create-topics: false
                      brokers: ${KAFKA_BROKER_DLQ://localhost:29095}
                      configuration:
                        sasl:
                          jaas:
                            config: ${KAFKA_SASL_JAAS_CONFIG_PRODUCER_RTD_DLQ_TRX}
                          mechanism: PLAIN
                        security:
                          protocol: SASL_SSL
                        default.key.serde: org.apache.kafka.common.serialization.Serdes$StringSerde
                        default.value.serde: org.apache.kafka.common.serialization.Serdes$StringSerde
        rtd-dlq-trx-consumer:
          type: kafka
          environment:
            spring:
              cloud:
                stream:
                  kafka:
                    binder:
                      auto-create-topics: false
                      brokers: ${KAFKA_BROKER_DLQ://localhost:29095}
                      configuration:
                        sasl:
                          jaas:
                            config: ${KAFKA_SASL_JAAS_CONFIG_CONSUMER_RTD_DLQ_TRX}
                          mechanism: PLAIN
                        security:
                          protocol: SASL_SSL
                        default.key.serde: org.apache.kafka.common.serialization.Serdes$StringSerde
                        default.value.serde: org.apache.kafka.common.serialization.Serdes$StringSerde
        blob-storage:
          type: kafka
          environment:
            spring:
              cloud:
                stream:
                  kafka:
                    binder:
                      auto-create-topics: false
                      brokers: ${KAFKA_BROKER://localhost:29095}
                      configuration:
                        sasl:
                          jaas:
                            config: ${KAFKA_SASL_JAAS_CONFIG_CONSUMER_BLOB_STORAGE_EVENTS}
                          mechanism: PLAIN
                        security:
                          protocol: SASL_SSL
                      consumerProperties:
                        key:
                          deserializer: org.apache.kafka.common.serialization.StringDeserializer
                        value:
                          deserializer: org.apache.kafka.common.serialization.StringDeserializer
# ---
# spring:
#   config:
#     activate:
#       on-profile: default
#   cloud:
#     stream:
#       bindings:
#         blobStorageConsumer-in-0: # name must match [handler name]-in-0
#           destination: rtd-platform-events
#           group: rtd-ingestor-consumer-group
#           content-type: application/json
#           binder: blob-storage-consumer
#         rtdTrxProducer-out-0: # name must match [handler name]-out-0
#           destination: rtd-trx
#           binder: rtd-trx-producer
#       binders:
#         blob-storage-consumer:
#           type: kafka
#           environment:
#             auto-create-topics: false
#             brokers: ${KAFKA_BROKER}
#             configuration:
#               sasl:
#                 jaas:
#                   config: ${KAFKA_SASL_JAAS_CONFIG_CONSUMER_BLOB_STORAGE_EVENTS}
#                 mechanism: PLAIN
#               security:
#                 protocol: SASL_SSL
#             consumerProperties:
#               key:
#                 deserializer: org.apache.kafka.common.serialization.StringDeserializer
#               value:
#                 deserializer: org.apache.kafka.common.serialization.StringDeserializer
#               socket:
#                 connection:
#                   setup:
#                     timeout:
#                       max:
#                         ms: 200000
#                       ms: 100000
#               request:
#                 timeout:
#                   ms: 60000
#               connections:
#                 max:
#                   idle:
#                     ms: 180000
#               max:
#                 partition:
#                   fetch:
#                     bytes: 10485760
#               session:
#                 timeout:
#                   ms: 10000
#               metadata:
#                 max:
#                   age:
#                     ms: 180000
#               # partition:
#               #   assignment:
#               #     strategy: org.apache.kafka.clients.consumer.RangeAssignor
#         rtd-trx-producer:
#           type: kafka
#           environment:
#             auto-create-topics: false
#             brokers: ${KAFKA_BROKER}
#             configuration:
#               sasl:
#                 jaas:
#                   config: ${KAFKA_SASL_JAAS_CONFIG_PRODUCER_RTD_TRX}
#                 mechanism: PLAIN
#               security:
#                 protocol: SASL_SSL
#             consumerProperties:
#               # key:
#               #   deserializer: org.apache.kafka.common.serialization.StringDeserializer
#               # value:
#               #   deserializer: org.apache.kafka.common.serialization.StringDeserializer
#               socket:
#                 connection:
#                   setup:
#                     timeout:
#                       max:
#                         ms: 200000
#                       ms: 100000
#               request:
#                 timeout:
#                   ms: 60000
#               connections:
#                 max:
#                   idle:
#                     ms: 180000
#               max:
#                 partition:
#                   fetch:
#                     bytes: 10485760
#               session:
#                 timeout:
#                   ms: 10000
#               metadata:
#                 max:
#                   age:
#                     ms: 180000
#               # partition:
#               #   assignment:
#               #     strategy: org.apache.kafka.clients.consumer.RangeAssignor
